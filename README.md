ğŸ“˜ Offline Multi-Agent AI System (Streamlit + Ollama)

A fully offline AI Multi-Agent System built using Streamlit, LangChain, and Ollama.
The application deploys three coordinated AI agents â€” Planner, Research, and Decision â€” all powered by a local LLM (Gemma 2B) without requiring any API keys or internet connectivity.

â­ Overview

This project demonstrates how lightweight, local LLMs can be orchestrated in a multi-agent workflow to break down tasks, analyze information, and produce a refined final output.
It serves as a foundation for offline AI assistants, research tools, and automation systems.

ğŸš€ Key Features

ğŸ§  Multi-Agent Intelligence

Planner Agent â†’ Task decomposition

Research Agent â†’ In-depth processing

Decision Agent â†’ Final answer generation

âš¡ Fully Offline Inference
Powered by Ollama and the Gemma:2B model

ğŸ¨ Modern Streamlit UI
Chat-style interface with structured agent responses

ğŸ” Zero API Keys & Privacy Friendly
All processing happens locally on the machine

ğŸ› ï¸ Tech Stack

Python 3.10+

Streamlit

LangChain Community LLMs

Ollama (local model runner)

Gemma 2B (fast, lightweight LLM)

ğŸ§© System Workflow
ğŸ§  Planner Agent

Breaks down the user request into step-by-step tasks.

ğŸ” Research Agent

Expands each step with detailed explanations.

ğŸ¤ Decision Agent

Generates the final refined output.

All agents interact with the local LLM using LangChain + Ollama.

ğŸ™Œ Acknowledgements

Project developed by Simran,
under the guidance of Kodi Prakash Senapati Sir.
